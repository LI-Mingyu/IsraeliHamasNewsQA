[
    {
        "label": "openai",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "openai",
        "description": "openai",
        "detail": "openai",
        "documentation": {}
    },
    {
        "label": "json",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "json",
        "description": "json",
        "detail": "json",
        "documentation": {}
    },
    {
        "label": "requests",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "requests",
        "description": "requests",
        "detail": "requests",
        "documentation": {}
    },
    {
        "label": "numpy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "numpy",
        "description": "numpy",
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "Redis",
        "importPath": "redis",
        "description": "redis",
        "isExtraImport": true,
        "detail": "redis",
        "documentation": {}
    },
    {
        "label": "Redis",
        "importPath": "redis",
        "description": "redis",
        "isExtraImport": true,
        "detail": "redis",
        "documentation": {}
    },
    {
        "label": "Query",
        "importPath": "redis.commands.search.query",
        "description": "redis.commands.search.query",
        "isExtraImport": true,
        "detail": "redis.commands.search.query",
        "documentation": {}
    },
    {
        "label": "Query",
        "importPath": "redis.commands.search.query",
        "description": "redis.commands.search.query",
        "isExtraImport": true,
        "detail": "redis.commands.search.query",
        "documentation": {}
    },
    {
        "label": "TextField",
        "importPath": "redis.commands.search.field",
        "description": "redis.commands.search.field",
        "isExtraImport": true,
        "detail": "redis.commands.search.field",
        "documentation": {}
    },
    {
        "label": "VectorField",
        "importPath": "redis.commands.search.field",
        "description": "redis.commands.search.field",
        "isExtraImport": true,
        "detail": "redis.commands.search.field",
        "documentation": {}
    },
    {
        "label": "NumericField",
        "importPath": "redis.commands.search.field",
        "description": "redis.commands.search.field",
        "isExtraImport": true,
        "detail": "redis.commands.search.field",
        "documentation": {}
    },
    {
        "label": "IndexDefinition",
        "importPath": "redis.commands.search.indexDefinition",
        "description": "redis.commands.search.indexDefinition",
        "isExtraImport": true,
        "detail": "redis.commands.search.indexDefinition",
        "documentation": {}
    },
    {
        "label": "IndexType",
        "importPath": "redis.commands.search.indexDefinition",
        "description": "redis.commands.search.indexDefinition",
        "isExtraImport": true,
        "detail": "redis.commands.search.indexDefinition",
        "documentation": {}
    },
    {
        "label": "time",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "time",
        "description": "time",
        "detail": "time",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "date",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "date",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timedelta",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "logging",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "logging",
        "description": "logging",
        "detail": "logging",
        "documentation": {}
    },
    {
        "label": "os",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os",
        "description": "os",
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "streamlit",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "streamlit",
        "description": "streamlit",
        "detail": "streamlit",
        "documentation": {}
    },
    {
        "label": "runtime",
        "importPath": "streamlit",
        "description": "streamlit",
        "isExtraImport": true,
        "detail": "streamlit",
        "documentation": {}
    },
    {
        "label": "tiktoken",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "tiktoken",
        "description": "tiktoken",
        "detail": "tiktoken",
        "documentation": {}
    },
    {
        "label": "get_script_run_ctx",
        "importPath": "streamlit.runtime.scriptrunner",
        "description": "streamlit.runtime.scriptrunner",
        "isExtraImport": true,
        "detail": "streamlit.runtime.scriptrunner",
        "documentation": {}
    },
    {
        "label": "json_gpt",
        "kind": 2,
        "importPath": "data_prepare",
        "description": "data_prepare",
        "peekOfCode": "def json_gpt(input: str):\n    completion = openai.ChatCompletion.create(\n        model=GPT_MODEL,\n        messages=[\n            {\"role\": \"system\", \"content\": \"Output only valid JSON\"},\n            {\"role\": \"user\", \"content\": input},\n        ],\n        temperature=0.5,\n    )\n    text = completion.choices[0].message.content",
        "detail": "data_prepare",
        "documentation": {}
    },
    {
        "label": "embeddings",
        "kind": 2,
        "importPath": "data_prepare",
        "description": "data_prepare",
        "peekOfCode": "def embeddings(input: List[str]) -> List[List[str]]:\n    response = openai.Embedding.create(model=\"text-embedding-ada-002\", input=input)\n    return [data.embedding for data in response.data]\n# Set up logging\nlogging.basicConfig(level=logging.INFO,\n                    format='%(asctime)s - %(levelname)s - %(message)s',\n                    datefmt='%Y-%m-%d %H:%M:%S')\n## The data preparing scripts begins here ##\n# As default we use fixed search queries which are human edited, \n# the queries can also be generated by GPT with the following pompt and function.",
        "detail": "data_prepare",
        "documentation": {}
    },
    {
        "label": "newsapi_key",
        "kind": 5,
        "importPath": "data_prepare",
        "description": "data_prepare",
        "peekOfCode": "newsapi_key = os.getenv(\"NEWSAPI_KEY\")\nif not newsapi_key:\n    logging.error(\"NEWSAPI_KEY is not set.\")\nnewsapi_endpoint = \"https://newsapi.org/v2/everything\"\nlanguage = 'zh'\n# Prepare the api_key to call OpenAI\nopenai_api_key = os.getenv(\"OPENAI_API_KEY\")\nif not openai_api_key:\n    logging.error(\"OPENAI_API_KEY is not set.\")\nelse:",
        "detail": "data_prepare",
        "documentation": {}
    },
    {
        "label": "newsapi_endpoint",
        "kind": 5,
        "importPath": "data_prepare",
        "description": "data_prepare",
        "peekOfCode": "newsapi_endpoint = \"https://newsapi.org/v2/everything\"\nlanguage = 'zh'\n# Prepare the api_key to call OpenAI\nopenai_api_key = os.getenv(\"OPENAI_API_KEY\")\nif not openai_api_key:\n    logging.error(\"OPENAI_API_KEY is not set.\")\nelse:\n    openai.api_key = openai_api_key\nGPT_MODEL = \"gpt-4\"\nINDEX_NAME = \"IranNewsOnline\"",
        "detail": "data_prepare",
        "documentation": {}
    },
    {
        "label": "language",
        "kind": 5,
        "importPath": "data_prepare",
        "description": "data_prepare",
        "peekOfCode": "language = 'zh'\n# Prepare the api_key to call OpenAI\nopenai_api_key = os.getenv(\"OPENAI_API_KEY\")\nif not openai_api_key:\n    logging.error(\"OPENAI_API_KEY is not set.\")\nelse:\n    openai.api_key = openai_api_key\nGPT_MODEL = \"gpt-4\"\nINDEX_NAME = \"IranNewsOnline\"\nVECTOR_DIM = 1536 ",
        "detail": "data_prepare",
        "documentation": {}
    },
    {
        "label": "openai_api_key",
        "kind": 5,
        "importPath": "data_prepare",
        "description": "data_prepare",
        "peekOfCode": "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\nif not openai_api_key:\n    logging.error(\"OPENAI_API_KEY is not set.\")\nelse:\n    openai.api_key = openai_api_key\nGPT_MODEL = \"gpt-4\"\nINDEX_NAME = \"IranNewsOnline\"\nVECTOR_DIM = 1536 \nDISTANCE_METRIC = \"COSINE\"   \n# Helper functions",
        "detail": "data_prepare",
        "documentation": {}
    },
    {
        "label": "GPT_MODEL",
        "kind": 5,
        "importPath": "data_prepare",
        "description": "data_prepare",
        "peekOfCode": "GPT_MODEL = \"gpt-4\"\nINDEX_NAME = \"IranNewsOnline\"\nVECTOR_DIM = 1536 \nDISTANCE_METRIC = \"COSINE\"   \n# Helper functions\ndef json_gpt(input: str):\n    completion = openai.ChatCompletion.create(\n        model=GPT_MODEL,\n        messages=[\n            {\"role\": \"system\", \"content\": \"Output only valid JSON\"},",
        "detail": "data_prepare",
        "documentation": {}
    },
    {
        "label": "INDEX_NAME",
        "kind": 5,
        "importPath": "data_prepare",
        "description": "data_prepare",
        "peekOfCode": "INDEX_NAME = \"IranNewsOnline\"\nVECTOR_DIM = 1536 \nDISTANCE_METRIC = \"COSINE\"   \n# Helper functions\ndef json_gpt(input: str):\n    completion = openai.ChatCompletion.create(\n        model=GPT_MODEL,\n        messages=[\n            {\"role\": \"system\", \"content\": \"Output only valid JSON\"},\n            {\"role\": \"user\", \"content\": input},",
        "detail": "data_prepare",
        "documentation": {}
    },
    {
        "label": "VECTOR_DIM",
        "kind": 5,
        "importPath": "data_prepare",
        "description": "data_prepare",
        "peekOfCode": "VECTOR_DIM = 1536 \nDISTANCE_METRIC = \"COSINE\"   \n# Helper functions\ndef json_gpt(input: str):\n    completion = openai.ChatCompletion.create(\n        model=GPT_MODEL,\n        messages=[\n            {\"role\": \"system\", \"content\": \"Output only valid JSON\"},\n            {\"role\": \"user\", \"content\": input},\n        ],",
        "detail": "data_prepare",
        "documentation": {}
    },
    {
        "label": "DISTANCE_METRIC",
        "kind": 5,
        "importPath": "data_prepare",
        "description": "data_prepare",
        "peekOfCode": "DISTANCE_METRIC = \"COSINE\"   \n# Helper functions\ndef json_gpt(input: str):\n    completion = openai.ChatCompletion.create(\n        model=GPT_MODEL,\n        messages=[\n            {\"role\": \"system\", \"content\": \"Output only valid JSON\"},\n            {\"role\": \"user\", \"content\": input},\n        ],\n        temperature=0.5,",
        "detail": "data_prepare",
        "documentation": {}
    },
    {
        "label": "queries",
        "kind": 5,
        "importPath": "data_prepare",
        "description": "data_prepare",
        "peekOfCode": "queries = ['Iran news',\n    'Iran current events',\n    'Iran politics',\n    'Iran economy',\n    'Iran culture',\n    'Iran history',\n    'Iran sanctions',\n    'Iran nuclear deal',\n    'Iran-US relations',\n    'Iran-China relations',",
        "detail": "data_prepare",
        "documentation": {}
    },
    {
        "label": "articles",
        "kind": 5,
        "importPath": "data_prepare",
        "description": "data_prepare",
        "peekOfCode": "articles = []\nheaders = {\"Authorization\": newsapi_key}\nfor i, query in enumerate(queries):\n    params = {\"q\": query, \"language\": language, \"pageSize\": 20}  # NewApiä½¿ç”¨â€˜pageSize'è€Œä¸æ˜¯'count'ï¼Œè¡¨ç¤ºæ¯é¡µè¿”å›çš„ç»“æœæ•°\n    # should use try here, however not doing so for simplicity for now\n    response = requests.get(newsapi_endpoint, headers=headers, params=params)\n    response.raise_for_status()\n    search_results = response.json()\n    articles.extend(search_results[\"articles\"])  # ä½¿ç”¨ extend æ¥æ·»åŠ åˆ—è¡¨å…ƒç´ , BingSearchAPIä¸­çš„valueå‚æ•°ç›¸å½“äºNewsAPIä¸­çš„articles\n    logging.info(f\"{i + 1} of {len(queries)} queries have been responsed. {len(articles)} articles have been collected.\")",
        "detail": "data_prepare",
        "documentation": {}
    },
    {
        "label": "headers",
        "kind": 5,
        "importPath": "data_prepare",
        "description": "data_prepare",
        "peekOfCode": "headers = {\"Authorization\": newsapi_key}\nfor i, query in enumerate(queries):\n    params = {\"q\": query, \"language\": language, \"pageSize\": 20}  # NewApiä½¿ç”¨â€˜pageSize'è€Œä¸æ˜¯'count'ï¼Œè¡¨ç¤ºæ¯é¡µè¿”å›çš„ç»“æœæ•°\n    # should use try here, however not doing so for simplicity for now\n    response = requests.get(newsapi_endpoint, headers=headers, params=params)\n    response.raise_for_status()\n    search_results = response.json()\n    articles.extend(search_results[\"articles\"])  # ä½¿ç”¨ extend æ¥æ·»åŠ åˆ—è¡¨å…ƒç´ , BingSearchAPIä¸­çš„valueå‚æ•°ç›¸å½“äºNewsAPIä¸­çš„articles\n    logging.info(f\"{i + 1} of {len(queries)} queries have been responsed. {len(articles)} articles have been collected.\")\n# remove duplicates",
        "detail": "data_prepare",
        "documentation": {}
    },
    {
        "label": "articles",
        "kind": 5,
        "importPath": "data_prepare",
        "description": "data_prepare",
        "peekOfCode": "articles = list({article[\"url\"]: article for article in articles}.values())\nlogging.info(f\"{len(articles)} articles after deduplication.\")\n# Prepare to connect to Redis\nredis_host = os.getenv('REDIS_HOST', 'localhost')  # default to 'localhost' if not set\nredis_port = os.getenv('REDIS_PORT', '6379')  # default to '6379' if not set\nredis_db = os.getenv('REDIS_DB', '0')  # default to '0' if not set. RediSearch only operates on the default (0) db\n # Instantiates a Redis client. decode_responses=False to avoid decoding the returned embedding vectors\nr = Redis(host=redis_host, port=redis_port, db=redis_db, decode_responses=False)\n# define RediSearch vector fields to use FLAT index\nembedding = VectorField(\"embedding\",",
        "detail": "data_prepare",
        "documentation": {}
    },
    {
        "label": "redis_host",
        "kind": 5,
        "importPath": "data_prepare",
        "description": "data_prepare",
        "peekOfCode": "redis_host = os.getenv('REDIS_HOST', 'localhost')  # default to 'localhost' if not set\nredis_port = os.getenv('REDIS_PORT', '6379')  # default to '6379' if not set\nredis_db = os.getenv('REDIS_DB', '0')  # default to '0' if not set. RediSearch only operates on the default (0) db\n # Instantiates a Redis client. decode_responses=False to avoid decoding the returned embedding vectors\nr = Redis(host=redis_host, port=redis_port, db=redis_db, decode_responses=False)\n# define RediSearch vector fields to use FLAT index\nembedding = VectorField(\"embedding\",\n    \"FLAT\", {\n        \"TYPE\": \"FLOAT32\",\n        \"DIM\": VECTOR_DIM,",
        "detail": "data_prepare",
        "documentation": {}
    },
    {
        "label": "redis_port",
        "kind": 5,
        "importPath": "data_prepare",
        "description": "data_prepare",
        "peekOfCode": "redis_port = os.getenv('REDIS_PORT', '6379')  # default to '6379' if not set\nredis_db = os.getenv('REDIS_DB', '0')  # default to '0' if not set. RediSearch only operates on the default (0) db\n # Instantiates a Redis client. decode_responses=False to avoid decoding the returned embedding vectors\nr = Redis(host=redis_host, port=redis_port, db=redis_db, decode_responses=False)\n# define RediSearch vector fields to use FLAT index\nembedding = VectorField(\"embedding\",\n    \"FLAT\", {\n        \"TYPE\": \"FLOAT32\",\n        \"DIM\": VECTOR_DIM,\n        \"DISTANCE_METRIC\": DISTANCE_METRIC",
        "detail": "data_prepare",
        "documentation": {}
    },
    {
        "label": "redis_db",
        "kind": 5,
        "importPath": "data_prepare",
        "description": "data_prepare",
        "peekOfCode": "redis_db = os.getenv('REDIS_DB', '0')  # default to '0' if not set. RediSearch only operates on the default (0) db\n # Instantiates a Redis client. decode_responses=False to avoid decoding the returned embedding vectors\nr = Redis(host=redis_host, port=redis_port, db=redis_db, decode_responses=False)\n# define RediSearch vector fields to use FLAT index\nembedding = VectorField(\"embedding\",\n    \"FLAT\", {\n        \"TYPE\": \"FLOAT32\",\n        \"DIM\": VECTOR_DIM,\n        \"DISTANCE_METRIC\": DISTANCE_METRIC\n    }",
        "detail": "data_prepare",
        "documentation": {}
    },
    {
        "label": "r",
        "kind": 5,
        "importPath": "data_prepare",
        "description": "data_prepare",
        "peekOfCode": "r = Redis(host=redis_host, port=redis_port, db=redis_db, decode_responses=False)\n# define RediSearch vector fields to use FLAT index\nembedding = VectorField(\"embedding\",\n    \"FLAT\", {\n        \"TYPE\": \"FLOAT32\",\n        \"DIM\": VECTOR_DIM,\n        \"DISTANCE_METRIC\": DISTANCE_METRIC\n    }\n)\n# Define RediSearch fields for each of the columns in the dataset",
        "detail": "data_prepare",
        "documentation": {}
    },
    {
        "label": "embedding",
        "kind": 5,
        "importPath": "data_prepare",
        "description": "data_prepare",
        "peekOfCode": "embedding = VectorField(\"embedding\",\n    \"FLAT\", {\n        \"TYPE\": \"FLOAT32\",\n        \"DIM\": VECTOR_DIM,\n        \"DISTANCE_METRIC\": DISTANCE_METRIC\n    }\n)\n# Define RediSearch fields for each of the columns in the dataset\n# This is where you should add any additional metadata you want to capture\npublishedAt = TextField(\"publishedAt\")  # NewsAPIä¸­\"å‘å¸ƒæ—¥æœŸ\"å‚æ•°ä¸º\"publishedAt\"",
        "detail": "data_prepare",
        "documentation": {}
    },
    {
        "label": "publishedAt",
        "kind": 5,
        "importPath": "data_prepare",
        "description": "data_prepare",
        "peekOfCode": "publishedAt = TextField(\"publishedAt\")  # NewsAPIä¸­\"å‘å¸ƒæ—¥æœŸ\"å‚æ•°ä¸º\"publishedAt\"\ntimeStamp = NumericField(\"timeStamp\")\nurl = TextField(\"url\")\ndescription = TextField(\"description\")\nfeilds = [publishedAt, timeStamp, url, description, embedding]\n# Update the whole index including documents\nindexDefinition = IndexDefinition(prefix=[INDEX_NAME], index_type=IndexType.HASH)\ntry:\n    r.ft(INDEX_NAME).dropindex(delete_documents=True)\nexcept Exception as e:",
        "detail": "data_prepare",
        "documentation": {}
    },
    {
        "label": "timeStamp",
        "kind": 5,
        "importPath": "data_prepare",
        "description": "data_prepare",
        "peekOfCode": "timeStamp = NumericField(\"timeStamp\")\nurl = TextField(\"url\")\ndescription = TextField(\"description\")\nfeilds = [publishedAt, timeStamp, url, description, embedding]\n# Update the whole index including documents\nindexDefinition = IndexDefinition(prefix=[INDEX_NAME], index_type=IndexType.HASH)\ntry:\n    r.ft(INDEX_NAME).dropindex(delete_documents=True)\nexcept Exception as e:\n    logging.error(f\"Error when deleting index from Redis: {e}\")",
        "detail": "data_prepare",
        "documentation": {}
    },
    {
        "label": "url",
        "kind": 5,
        "importPath": "data_prepare",
        "description": "data_prepare",
        "peekOfCode": "url = TextField(\"url\")\ndescription = TextField(\"description\")\nfeilds = [publishedAt, timeStamp, url, description, embedding]\n# Update the whole index including documents\nindexDefinition = IndexDefinition(prefix=[INDEX_NAME], index_type=IndexType.HASH)\ntry:\n    r.ft(INDEX_NAME).dropindex(delete_documents=True)\nexcept Exception as e:\n    logging.error(f\"Error when deleting index from Redis: {e}\")\ntry:",
        "detail": "data_prepare",
        "documentation": {}
    },
    {
        "label": "description",
        "kind": 5,
        "importPath": "data_prepare",
        "description": "data_prepare",
        "peekOfCode": "description = TextField(\"description\")\nfeilds = [publishedAt, timeStamp, url, description, embedding]\n# Update the whole index including documents\nindexDefinition = IndexDefinition(prefix=[INDEX_NAME], index_type=IndexType.HASH)\ntry:\n    r.ft(INDEX_NAME).dropindex(delete_documents=True)\nexcept Exception as e:\n    logging.error(f\"Error when deleting index from Redis: {e}\")\ntry:\n    r.ft(INDEX_NAME).create_index(fields=feilds, definition=indexDefinition)",
        "detail": "data_prepare",
        "documentation": {}
    },
    {
        "label": "feilds",
        "kind": 5,
        "importPath": "data_prepare",
        "description": "data_prepare",
        "peekOfCode": "feilds = [publishedAt, timeStamp, url, description, embedding]\n# Update the whole index including documents\nindexDefinition = IndexDefinition(prefix=[INDEX_NAME], index_type=IndexType.HASH)\ntry:\n    r.ft(INDEX_NAME).dropindex(delete_documents=True)\nexcept Exception as e:\n    logging.error(f\"Error when deleting index from Redis: {e}\")\ntry:\n    r.ft(INDEX_NAME).create_index(fields=feilds, definition=indexDefinition)\nexcept Exception as e:",
        "detail": "data_prepare",
        "documentation": {}
    },
    {
        "label": "indexDefinition",
        "kind": 5,
        "importPath": "data_prepare",
        "description": "data_prepare",
        "peekOfCode": "indexDefinition = IndexDefinition(prefix=[INDEX_NAME], index_type=IndexType.HASH)\ntry:\n    r.ft(INDEX_NAME).dropindex(delete_documents=True)\nexcept Exception as e:\n    logging.error(f\"Error when deleting index from Redis: {e}\")\ntry:\n    r.ft(INDEX_NAME).create_index(fields=feilds, definition=indexDefinition)\nexcept Exception as e:\n    raise(e)\nlogging.info(f\"RediSearch index {INDEX_NAME} has been created/updated.\")",
        "detail": "data_prepare",
        "documentation": {}
    },
    {
        "label": "indexes",
        "kind": 5,
        "importPath": "data_prepare",
        "description": "data_prepare",
        "peekOfCode": "indexes = r.execute_command(f'KEYS {INDEX_NAME}:*')\nlogging.info(f\"{len(indexes)} articles have been added to RediSearch index {INDEX_NAME}.\")\n# Test search\n# test_question = \"æœ€æ–°å±€åŠ¿å¦‚ä½•ï¼Ÿ\"\n# query_embedding = openai.Embedding.create(input=test_question, model=\"text-embedding-ada-002\")[\"data\"][0][\"embedding\"]\n# query_vec = np.array(query_embedding).astype(np.float32).tobytes()\n# # Prepare the query\n# query_base = (Query(\"*=>[KNN 20 @embedding $vec as score]\").sort_by(\"timeStamp\", asc=False).paging(0, 20).return_fields(\"score\", \"url\", \"datePublished\", \"description\").dialect(2))\n# query_param = {\"vec\": query_vec}\n# query_results = r.ft(INDEX_NAME).search(query_base, query_param).docs",
        "detail": "data_prepare",
        "documentation": {}
    },
    {
        "label": "SessionInfoAdapter",
        "kind": 6,
        "importPath": "streamlit_app",
        "description": "streamlit_app",
        "peekOfCode": "class SessionInfoAdapter(logging.LoggerAdapter):\n    def process(self, msg, kwargs):\n        return f\"{self.extra['remote_ip']} - {self.extra['session_id']} - {msg}\", kwargs\n# Set up logging\nlogging.basicConfig(level=logging.INFO,\n                    format='%(asctime)s - %(levelname)s - %(message)s',\n                    datefmt='%Y-%m-%d %H:%M:%S')\nsession_info = get_session_info()\nlogger = SessionInfoAdapter(logging.getLogger(), session_info)\n# The streamlit script starts here",
        "detail": "streamlit_app",
        "documentation": {}
    },
    {
        "label": "topic_correlation",
        "kind": 2,
        "importPath": "streamlit_app",
        "description": "streamlit_app",
        "peekOfCode": "def topic_correlation(query, topic=TOPIC):\n    \"\"\"Calculate the correlation between the query and the topic.\"\"\"\n    try:\n        query_embedding = openai.Embedding.create(input=query, model=\"text-embedding-ada-002\")[\"data\"][0][\"embedding\"]\n        topic_embedding = openai.Embedding.create(input=topic, model=\"text-embedding-ada-002\")[\"data\"][0][\"embedding\"]\n        return np.dot(query_embedding, topic_embedding)\n    except Exception as e:\n        logging.error(f\"Error calculating correlation: {e}\")\n        return 0\ndef get_session_info():",
        "detail": "streamlit_app",
        "documentation": {}
    },
    {
        "label": "get_session_info",
        "kind": 2,
        "importPath": "streamlit_app",
        "description": "streamlit_app",
        "peekOfCode": "def get_session_info():\n    \"\"\"Get the session id and the remote ip.\"\"\"\n    try:\n        ctx = get_script_run_ctx()\n        if ctx is None:\n            return {'session_id': 'unknown', 'remote_ip': 'unknown'}\n        session_info = runtime.get_instance().get_client(ctx.session_id)\n        if session_info is None:\n            return {'session_id': 'unknown', 'remote_ip': 'unknown'}\n    except Exception as e:",
        "detail": "streamlit_app",
        "documentation": {}
    },
    {
        "label": "GPT_MODEL",
        "kind": 5,
        "importPath": "streamlit_app",
        "description": "streamlit_app",
        "peekOfCode": "GPT_MODEL = \"gpt-4\"\nVECTOR_DIM = 1536 \nDISTANCE_METRIC = \"COSINE\"  \nINDEX_NAME = \"IranNewsOnline\"\nTOPIC = \"ä¼Šæœ— Iran\"\ndef topic_correlation(query, topic=TOPIC):\n    \"\"\"Calculate the correlation between the query and the topic.\"\"\"\n    try:\n        query_embedding = openai.Embedding.create(input=query, model=\"text-embedding-ada-002\")[\"data\"][0][\"embedding\"]\n        topic_embedding = openai.Embedding.create(input=topic, model=\"text-embedding-ada-002\")[\"data\"][0][\"embedding\"]",
        "detail": "streamlit_app",
        "documentation": {}
    },
    {
        "label": "VECTOR_DIM",
        "kind": 5,
        "importPath": "streamlit_app",
        "description": "streamlit_app",
        "peekOfCode": "VECTOR_DIM = 1536 \nDISTANCE_METRIC = \"COSINE\"  \nINDEX_NAME = \"IranNewsOnline\"\nTOPIC = \"ä¼Šæœ— Iran\"\ndef topic_correlation(query, topic=TOPIC):\n    \"\"\"Calculate the correlation between the query and the topic.\"\"\"\n    try:\n        query_embedding = openai.Embedding.create(input=query, model=\"text-embedding-ada-002\")[\"data\"][0][\"embedding\"]\n        topic_embedding = openai.Embedding.create(input=topic, model=\"text-embedding-ada-002\")[\"data\"][0][\"embedding\"]\n        return np.dot(query_embedding, topic_embedding)",
        "detail": "streamlit_app",
        "documentation": {}
    },
    {
        "label": "DISTANCE_METRIC",
        "kind": 5,
        "importPath": "streamlit_app",
        "description": "streamlit_app",
        "peekOfCode": "DISTANCE_METRIC = \"COSINE\"  \nINDEX_NAME = \"IranNewsOnline\"\nTOPIC = \"ä¼Šæœ— Iran\"\ndef topic_correlation(query, topic=TOPIC):\n    \"\"\"Calculate the correlation between the query and the topic.\"\"\"\n    try:\n        query_embedding = openai.Embedding.create(input=query, model=\"text-embedding-ada-002\")[\"data\"][0][\"embedding\"]\n        topic_embedding = openai.Embedding.create(input=topic, model=\"text-embedding-ada-002\")[\"data\"][0][\"embedding\"]\n        return np.dot(query_embedding, topic_embedding)\n    except Exception as e:",
        "detail": "streamlit_app",
        "documentation": {}
    },
    {
        "label": "INDEX_NAME",
        "kind": 5,
        "importPath": "streamlit_app",
        "description": "streamlit_app",
        "peekOfCode": "INDEX_NAME = \"IranNewsOnline\"\nTOPIC = \"ä¼Šæœ— Iran\"\ndef topic_correlation(query, topic=TOPIC):\n    \"\"\"Calculate the correlation between the query and the topic.\"\"\"\n    try:\n        query_embedding = openai.Embedding.create(input=query, model=\"text-embedding-ada-002\")[\"data\"][0][\"embedding\"]\n        topic_embedding = openai.Embedding.create(input=topic, model=\"text-embedding-ada-002\")[\"data\"][0][\"embedding\"]\n        return np.dot(query_embedding, topic_embedding)\n    except Exception as e:\n        logging.error(f\"Error calculating correlation: {e}\")",
        "detail": "streamlit_app",
        "documentation": {}
    },
    {
        "label": "TOPIC",
        "kind": 5,
        "importPath": "streamlit_app",
        "description": "streamlit_app",
        "peekOfCode": "TOPIC = \"ä¼Šæœ— Iran\"\ndef topic_correlation(query, topic=TOPIC):\n    \"\"\"Calculate the correlation between the query and the topic.\"\"\"\n    try:\n        query_embedding = openai.Embedding.create(input=query, model=\"text-embedding-ada-002\")[\"data\"][0][\"embedding\"]\n        topic_embedding = openai.Embedding.create(input=topic, model=\"text-embedding-ada-002\")[\"data\"][0][\"embedding\"]\n        return np.dot(query_embedding, topic_embedding)\n    except Exception as e:\n        logging.error(f\"Error calculating correlation: {e}\")\n        return 0",
        "detail": "streamlit_app",
        "documentation": {}
    },
    {
        "label": "session_info",
        "kind": 5,
        "importPath": "streamlit_app",
        "description": "streamlit_app",
        "peekOfCode": "session_info = get_session_info()\nlogger = SessionInfoAdapter(logging.getLogger(), session_info)\n# The streamlit script starts here\nlogger.info(\"Starting Streamlit script ...\")\n# Prepare to connect to Redis\nredis_host = os.getenv('REDIS_HOST', 'localhost')  # default to 'localhost' if not set\nredis_port = os.getenv('REDIS_PORT', '6379')  # default to '6379' if not set\nredis_db = os.getenv('REDIS_DB', '0')  # default to '0' if not set. RediSearch only operates on the default (0) db\n # Instantiates a Redis client. decode_responses=False to avoid decoding the returned embedding vectors\nr = Redis(host=redis_host, port=redis_port, db=redis_db, decode_responses=False)",
        "detail": "streamlit_app",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "streamlit_app",
        "description": "streamlit_app",
        "peekOfCode": "logger = SessionInfoAdapter(logging.getLogger(), session_info)\n# The streamlit script starts here\nlogger.info(\"Starting Streamlit script ...\")\n# Prepare to connect to Redis\nredis_host = os.getenv('REDIS_HOST', 'localhost')  # default to 'localhost' if not set\nredis_port = os.getenv('REDIS_PORT', '6379')  # default to '6379' if not set\nredis_db = os.getenv('REDIS_DB', '0')  # default to '0' if not set. RediSearch only operates on the default (0) db\n # Instantiates a Redis client. decode_responses=False to avoid decoding the returned embedding vectors\nr = Redis(host=redis_host, port=redis_port, db=redis_db, decode_responses=False)\n# æŸ¥æ‰¾æœ€æ–°çš„æ¶ˆæ¯",
        "detail": "streamlit_app",
        "documentation": {}
    },
    {
        "label": "redis_host",
        "kind": 5,
        "importPath": "streamlit_app",
        "description": "streamlit_app",
        "peekOfCode": "redis_host = os.getenv('REDIS_HOST', 'localhost')  # default to 'localhost' if not set\nredis_port = os.getenv('REDIS_PORT', '6379')  # default to '6379' if not set\nredis_db = os.getenv('REDIS_DB', '0')  # default to '0' if not set. RediSearch only operates on the default (0) db\n # Instantiates a Redis client. decode_responses=False to avoid decoding the returned embedding vectors\nr = Redis(host=redis_host, port=redis_port, db=redis_db, decode_responses=False)\n# æŸ¥æ‰¾æœ€æ–°çš„æ¶ˆæ¯\nquery_latest = Query(\"*\").sort_by(\"timeStamp\", asc=False).return_fields(\"publishedAt\").paging(0, 1)  #paging(0, 1)é™åˆ¶è¿”å›ä¸€æ¡è®°å½•\ntry:\n    latest_search_result = r.ft(INDEX_NAME).search(query_latest).docs[0]\n    # latest_date = datetime.strptime(latest_search_result.publishedAt, '%Y-%m-%dT%H:%M:%S')  # å¾…ä¿®æ”¹ï¼Œè‹¥é‡‡ç”¨ä¸Šè¿°çš„æ ¼å¼ï¼Œè¿˜å¾—ç”¨ä¸€ä¸ªå‡½æ•°è¿›è¡Œè½¬æ¢",
        "detail": "streamlit_app",
        "documentation": {}
    },
    {
        "label": "redis_port",
        "kind": 5,
        "importPath": "streamlit_app",
        "description": "streamlit_app",
        "peekOfCode": "redis_port = os.getenv('REDIS_PORT', '6379')  # default to '6379' if not set\nredis_db = os.getenv('REDIS_DB', '0')  # default to '0' if not set. RediSearch only operates on the default (0) db\n # Instantiates a Redis client. decode_responses=False to avoid decoding the returned embedding vectors\nr = Redis(host=redis_host, port=redis_port, db=redis_db, decode_responses=False)\n# æŸ¥æ‰¾æœ€æ–°çš„æ¶ˆæ¯\nquery_latest = Query(\"*\").sort_by(\"timeStamp\", asc=False).return_fields(\"publishedAt\").paging(0, 1)  #paging(0, 1)é™åˆ¶è¿”å›ä¸€æ¡è®°å½•\ntry:\n    latest_search_result = r.ft(INDEX_NAME).search(query_latest).docs[0]\n    # latest_date = datetime.strptime(latest_search_result.publishedAt, '%Y-%m-%dT%H:%M:%S')  # å¾…ä¿®æ”¹ï¼Œè‹¥é‡‡ç”¨ä¸Šè¿°çš„æ ¼å¼ï¼Œè¿˜å¾—ç”¨ä¸€ä¸ªå‡½æ•°è¿›è¡Œè½¬æ¢\n    latest_date = datetime.strptime(latest_search_result.publishedAt, '%Y-%m-%dT%H:%M:%SZ')",
        "detail": "streamlit_app",
        "documentation": {}
    },
    {
        "label": "redis_db",
        "kind": 5,
        "importPath": "streamlit_app",
        "description": "streamlit_app",
        "peekOfCode": "redis_db = os.getenv('REDIS_DB', '0')  # default to '0' if not set. RediSearch only operates on the default (0) db\n # Instantiates a Redis client. decode_responses=False to avoid decoding the returned embedding vectors\nr = Redis(host=redis_host, port=redis_port, db=redis_db, decode_responses=False)\n# æŸ¥æ‰¾æœ€æ–°çš„æ¶ˆæ¯\nquery_latest = Query(\"*\").sort_by(\"timeStamp\", asc=False).return_fields(\"publishedAt\").paging(0, 1)  #paging(0, 1)é™åˆ¶è¿”å›ä¸€æ¡è®°å½•\ntry:\n    latest_search_result = r.ft(INDEX_NAME).search(query_latest).docs[0]\n    # latest_date = datetime.strptime(latest_search_result.publishedAt, '%Y-%m-%dT%H:%M:%S')  # å¾…ä¿®æ”¹ï¼Œè‹¥é‡‡ç”¨ä¸Šè¿°çš„æ ¼å¼ï¼Œè¿˜å¾—ç”¨ä¸€ä¸ªå‡½æ•°è¿›è¡Œè½¬æ¢\n    latest_date = datetime.strptime(latest_search_result.publishedAt, '%Y-%m-%dT%H:%M:%SZ')\n    latest_date = latest_date + timedelta(hours=8) # Convert to Beijing time",
        "detail": "streamlit_app",
        "documentation": {}
    },
    {
        "label": "r",
        "kind": 5,
        "importPath": "streamlit_app",
        "description": "streamlit_app",
        "peekOfCode": "r = Redis(host=redis_host, port=redis_port, db=redis_db, decode_responses=False)\n# æŸ¥æ‰¾æœ€æ–°çš„æ¶ˆæ¯\nquery_latest = Query(\"*\").sort_by(\"timeStamp\", asc=False).return_fields(\"publishedAt\").paging(0, 1)  #paging(0, 1)é™åˆ¶è¿”å›ä¸€æ¡è®°å½•\ntry:\n    latest_search_result = r.ft(INDEX_NAME).search(query_latest).docs[0]\n    # latest_date = datetime.strptime(latest_search_result.publishedAt, '%Y-%m-%dT%H:%M:%S')  # å¾…ä¿®æ”¹ï¼Œè‹¥é‡‡ç”¨ä¸Šè¿°çš„æ ¼å¼ï¼Œè¿˜å¾—ç”¨ä¸€ä¸ªå‡½æ•°è¿›è¡Œè½¬æ¢\n    latest_date = datetime.strptime(latest_search_result.publishedAt, '%Y-%m-%dT%H:%M:%SZ')\n    latest_date = latest_date + timedelta(hours=8) # Convert to Beijing time\n    latest_date = latest_date.strftime(\"%Y-%m-%d %H:%M\")\nexcept Exception as e:",
        "detail": "streamlit_app",
        "documentation": {}
    },
    {
        "label": "query_latest",
        "kind": 5,
        "importPath": "streamlit_app",
        "description": "streamlit_app",
        "peekOfCode": "query_latest = Query(\"*\").sort_by(\"timeStamp\", asc=False).return_fields(\"publishedAt\").paging(0, 1)  #paging(0, 1)é™åˆ¶è¿”å›ä¸€æ¡è®°å½•\ntry:\n    latest_search_result = r.ft(INDEX_NAME).search(query_latest).docs[0]\n    # latest_date = datetime.strptime(latest_search_result.publishedAt, '%Y-%m-%dT%H:%M:%S')  # å¾…ä¿®æ”¹ï¼Œè‹¥é‡‡ç”¨ä¸Šè¿°çš„æ ¼å¼ï¼Œè¿˜å¾—ç”¨ä¸€ä¸ªå‡½æ•°è¿›è¡Œè½¬æ¢\n    latest_date = datetime.strptime(latest_search_result.publishedAt, '%Y-%m-%dT%H:%M:%SZ')\n    latest_date = latest_date + timedelta(hours=8) # Convert to Beijing time\n    latest_date = latest_date.strftime(\"%Y-%m-%d %H:%M\")\nexcept Exception as e:\n    logger.error(f\"Error querying Reids: {e}\")\n    st.error(\"æ— æ³•ä»æ•°æ®åº“ä¸­è·å–æ•°æ®ï¼Œè¿™å¾ˆå¯èƒ½æ˜¯ç³»ç»Ÿæ•…éšœå¯¼è‡´ï¼Œè¯·è”ç³»æˆ‘çš„ä¸»äººã€‚\")",
        "detail": "streamlit_app",
        "documentation": {}
    },
    {
        "label": "n_docs_in_index",
        "kind": 5,
        "importPath": "streamlit_app",
        "description": "streamlit_app",
        "peekOfCode": "n_docs_in_index = r.ft(INDEX_NAME).info()[\"num_docs\"]\nst.set_page_config(\n    page_title=\"ä¸€ä¸ªå…³æ³¨ä¼Šæœ—å±€åŠ¿çš„AI\",\n    page_icon=\"ğŸ’¥\",\n)\n# st.subheader(\"å·´ä»¥åŠ¨æ€å…¨çŸ¥é“\") \nst.write(f\"\"\"\n    æˆ‘æ˜¯ä¸€ä¸ªå…³æ³¨ä¼Šæœ—å±€åŠ¿çš„AIï¼Œæˆ‘çš„ä¿¡æ¯æ¥æºæ˜¯**NewsAPI**æ–°é—»æœç´¢ï¼Œæ¬¢è¿å‘æˆ‘æé—®æˆ–å’Œæˆ‘è®¨è®ºã€‚\n    æˆ‘ä¼šéš”ä¸€æ®µæ—¶é—´æ ¹æ®äº’è”ç½‘ä¸Šçš„æ¶ˆæ¯åˆ†æä¼Šæœ—çš„æœ€æ–°å½¢åŠ¿ï¼Œæˆ‘çš„æ•°æ®æœ€åä¸€æ¬¡æ›´æ–°äºåŒ—äº¬æ—¶é—´**{latest_date}**ã€‚åœ¨è¿™æ¬¡æ•°æ®æ›´æ–°ä¸­ï¼Œæˆ‘æœç´¢å¹¶é˜…è¯»äº†**{n_docs_in_index}**æ¡æ–°é—»ã€‚\n    æˆ‘è¿˜åœ¨å­¦ä¹ ä¸­ï¼Œå¦‚æœä½ è§‰å¾—æˆ‘çš„å›ç­”æœ‰ä»»ä½•é”™è¯¯æˆ–ä¸å¦¥ï¼Œè¯·è”ç³»æˆ‘çš„ä¸»äººï¼šmingyu.li.cn@gmail.com",
        "detail": "streamlit_app",
        "documentation": {}
    },
    {
        "label": "openai_api_key",
        "kind": 5,
        "importPath": "streamlit_app",
        "description": "streamlit_app",
        "peekOfCode": "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\nif not openai_api_key:\n    logger.error(\"KEY is not set.\")\n    st.error('KEYæœªè®¾ç½®ï¼Œè¯·è”ç³»æˆ‘çš„ä¸»äººã€‚')\n    st.stop() \nelse:\n    openai.api_key = openai_api_key\n# User-provided prompt\nif user_prompt := st.chat_input('åœ¨æ­¤è¾“å…¥æ‚¨çš„é—®é¢˜'):\n    user_prompt_topic_corr = topic_correlation(user_prompt)",
        "detail": "streamlit_app",
        "documentation": {}
    }
]