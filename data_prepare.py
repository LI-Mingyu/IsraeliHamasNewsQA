# imports and constants
import openai
import json
import requests    # 用于网络请求的模块，主要用来模拟浏览器发请求
import numpy as np
from redis import Redis
from redis.commands.search.query import Query
from redis.commands.search.field import (
    TextField,
    VectorField,
    NumericField
)
from redis.commands.search.indexDefinition import (
    IndexDefinition,
    IndexType
)
import time
from datetime import datetime, date
from typing import List
import logging
import os

newsapi_key = os.getenv("NEWSAPI_KEY")
if not newsapi_key:
    logging.error("NEWSAPI_KEY is not set.")
newsapi_endpoint = "https://newsapi.org/v2/everything"

language = 'zh'

# Prepare the api_key to call OpenAI
openai_api_key = os.getenv("OPENAI_API_KEY")
if not openai_api_key:
    logging.error("OPENAI_API_KEY is not set.")
else:
    openai.api_key = openai_api_key
GPT_MODEL = "gpt-4"

INDEX_NAME = "IranNewsOnline"
VECTOR_DIM = 1536 
DISTANCE_METRIC = "COSINE"   

# Helper functions
def json_gpt(input: str):
    completion = openai.ChatCompletion.create(
        model=GPT_MODEL,
        messages=[
            {"role": "system", "content": "Output only valid JSON"},
            {"role": "user", "content": input},
        ],
        temperature=0.5,
    )

    text = completion.choices[0].message.content
    parsed = json.loads(text)

    return parsed

def embeddings(input: List[str]) -> List[List[str]]:
    response = openai.Embedding.create(model="text-embedding-ada-002", input=input)
    return [data.embedding for data in response.data]

# Set up logging
logging.basicConfig(level=logging.INFO,
                    format='%(asctime)s - %(levelname)s - %(message)s',
                    datefmt='%Y-%m-%d %H:%M:%S')

## The data preparing scripts begins here ##

# As default we use fixed search queries which are human edited, 
# the queries can also be generated by GPT with the following pompt and function.
queries = ['Iran news',
    'Iran current events',
    'Iran politics',
    'Iran economy',
    'Iran culture',
    'Iran history',
    'Iran sanctions',
    'Iran nuclear deal',
    'Iran-US relations',
    'Iran-China relations',
    'Iran and Middle East',
    'Iran conflict',
    'Iran protests',
    'Iran and oil',
    'Iran military',
    'Iran elections',
    '伊朗新闻',
    '伊朗当前事件',
    '伊朗政治',
    '伊朗经济',
    '伊朗文化',
    '伊朗历史',
    '伊朗制裁',
    '伊朗核协议',
    '伊朗与美国关系',
    '伊朗冲突',
    '伊朗抗议',
    '伊朗石油',
    '伊朗军事',
    '伊朗选举']

# QUERIES_INPUT = """
# You have access to a search API that returns recent news articles.
# The background is Israeli-Palestinian situation and recent Israeli-Hamas conflict began on Oct. 7, 2023.
# Generate an array of search queries that are relevant to this topic both in English and Simplified Chinese.
# Use a variation of related keywords for the queries, trying to be as general as possible.
# Include as many queries as you can think of, including and excluding terms.
# For example, include queries like ['keyword_1 keyword_2', 'keyword_1', 'keyword_2'].

# Format: {{"queries": ["query_1", "query_2", "query_3"]}}
# """

# queries = json_gpt(QUERIES_INPUT)["queries"]

articles = []
headers = {"Authorization": newsapi_key}
for i, query in enumerate(queries):
    params = {"q": query, "language": language, "pageSize": 20}  # NewApi使用‘pageSize'而不是'count'，表示每页返回的结果数
    # should use try here, however not doing so for simplicity for now
    response = requests.get(newsapi_endpoint, headers=headers, params=params)
    response.raise_for_status()
    search_results = response.json()
    articles.extend(search_results["articles"])  # 使用 extend 来添加列表元素, BingSearchAPI中的value参数相当于NewsAPI中的articles
    logging.info(f"{i + 1} of {len(queries)} queries have been responsed. {len(articles)} articles have been collected.")
# remove duplicates
articles = list({article["url"]: article for article in articles}.values())
logging.info(f"{len(articles)} articles after deduplication.")

# Prepare to connect to Redis
redis_host = os.getenv('REDIS_HOST', 'localhost')  # default to 'localhost' if not set
redis_port = os.getenv('REDIS_PORT', '6379')  # default to '6379' if not set
redis_db = os.getenv('REDIS_DB', '0')  # default to '0' if not set. RediSearch only operates on the default (0) db
 # Instantiates a Redis client. decode_responses=False to avoid decoding the returned embedding vectors
r = Redis(host=redis_host, port=redis_port, db=redis_db, decode_responses=False)
# define RediSearch vector fields to use FLAT index
embedding = VectorField("embedding",
    "FLAT", {
        "TYPE": "FLOAT32",
        "DIM": VECTOR_DIM,
        "DISTANCE_METRIC": DISTANCE_METRIC
    }
)
# Define RediSearch fields for each of the columns in the dataset
# This is where you should add any additional metadata you want to capture

publishedAt = TextField("publishedAt")  # NewsAPI中"发布日期"参数为"publishedAt"
timeStamp = NumericField("timeStamp")
url = TextField("url")
description = TextField("description")
feilds = [publishedAt, timeStamp, url, description, embedding]
# Update the whole index including documents
indexDefinition = IndexDefinition(prefix=[INDEX_NAME], index_type=IndexType.HASH)

try:
    r.ft(INDEX_NAME).dropindex(delete_documents=True)
except Exception as e:
    logging.error(f"Error when deleting index from Redis: {e}")
try:
    r.ft(INDEX_NAME).create_index(fields=feilds, definition=indexDefinition)
except Exception as e:
    raise(e)
logging.info(f"RediSearch index {INDEX_NAME} has been created/updated.")

for article in articles:
    try:
        # Create embedding with GPT(ada)
        embedding = openai.Embedding.create(input=article["description"], model="text-embedding-ada-002")["data"][0]["embedding"]
    except Exception as e:
        logging.error(f"Error when creating embedding: {e}")
        continue
    # Prepare embedding vector for RediSearch
    embedding = np.array(embedding).astype(np.float32).tobytes()
    date_obj = datetime.strptime(article["publishedAt"][:-2], '%Y-%m-%dT%H:%M:%S')  # 匹配格式
    timeStamp = time.mktime(date_obj.timetuple())
    # Add to RediSearch index
    key = f'{INDEX_NAME}:{article["url"]}'
    try:
        r.hset(key, mapping={'publishedAt': article["publishedAt"], 'timeStamp': timeStamp, 'url': article["url"], 'description': article["description"], 'embedding': embedding})
    except Exception as e:
        logging.error(f"Error when adding articles to Redis: {e}")
        continue

indexes = r.execute_command(f'KEYS {INDEX_NAME}:*')
logging.info(f"{len(indexes)} articles have been added to RediSearch index {INDEX_NAME}.")

# Test search
# test_question = "最新局势如何？"
# query_embedding = openai.Embedding.create(input=test_question, model="text-embedding-ada-002")["data"][0]["embedding"]
# query_vec = np.array(query_embedding).astype(np.float32).tobytes()
# # Prepare the query
# query_base = (Query("*=>[KNN 20 @embedding $vec as score]").sort_by("timeStamp", asc=False).paging(0, 20).return_fields("score", "url", "datePublished", "description").dialect(2))
# query_param = {"vec": query_vec}
# query_results = r.ft(INDEX_NAME).search(query_base, query_param).docs

# 用于测试
# for article in articles:
#     print(article["publishedAt"], article["url"], article["description"])
#     print()